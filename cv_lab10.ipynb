{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOogBqd4C6wk"
      },
      "source": [
        "210648- Muhammad Umar Riaz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlSXxyYe_aqY",
        "outputId": "dababffd-acb7-4f86-bd25-251de23fb8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python opencv-contrib-python scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teBKPzXzClaY"
      },
      "source": [
        "Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAdbLNmA_zQc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Peliculas/fights'\n",
        "videos = [os.path.join(data_dir, v) for v in os.listdir(data_dir)]\n",
        "\n",
        "train_videos, test_videos = train_test_split(videos, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "for video in train_videos:\n",
        "    shutil.copy(video, train_dir)\n",
        "for video in test_videos:\n",
        "    shutil.copy(video, test_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Lgs30SCmtu"
      },
      "source": [
        "Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSixtWf6_7Wl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    sift = cv2.SIFT_create()\n",
        "    all_descriptors = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        kp, des = sift.detectAndCompute(gray, None)\n",
        "        if des is not None:\n",
        "            all_descriptors.append(des)\n",
        "\n",
        "    cap.release()\n",
        "    return np.vstack(all_descriptors) if all_descriptors else None\n",
        "\n",
        "# Extract features from all training videos\n",
        "train_descriptors = []\n",
        "for video in train_videos:\n",
        "    des = extract_features(video)\n",
        "    if des is not None:\n",
        "        train_descriptors.append(des)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZ4DUiTCp2B"
      },
      "source": [
        "Codebook Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNdWl_f_91H",
        "outputId": "773cddfa-fb51-4e96-d52b-e5b94f4630bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Flatten the list of descriptors\n",
        "all_descriptors = np.vstack(train_descriptors)\n",
        "\n",
        "# Define the number of clusters (codebook size)\n",
        "num_clusters = 500\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(all_descriptors)\n",
        "\n",
        "# Save the codebook\n",
        "codebook = kmeans.cluster_centers_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s56MNibhCsyy"
      },
      "source": [
        "Histogram Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aGLCwMaAIb1"
      },
      "outputs": [],
      "source": [
        "def compute_histogram(descriptors, codebook):\n",
        "    histogram = np.zeros(len(codebook))\n",
        "    if descriptors is not None:\n",
        "        predictions = kmeans.predict(descriptors)\n",
        "        for pred in predictions:\n",
        "            histogram[pred] += 1\n",
        "    return histogram\n",
        "\n",
        "# Compute histograms for training videos\n",
        "train_histograms = []\n",
        "train_labels = []  # Assuming you have labels\n",
        "\n",
        "for video in train_videos:\n",
        "    des = extract_features(video)\n",
        "    hist = compute_histogram(des, codebook)\n",
        "    train_histograms.append(hist)\n",
        "    # Add code to append the label for the video\n",
        "    # train_labels.append(label)\n",
        "\n",
        "# Repeat for test videos\n",
        "test_histograms = []\n",
        "test_labels = []\n",
        "\n",
        "for video in test_videos:\n",
        "    des = extract_features(video)\n",
        "    hist = compute_histogram(des, codebook)\n",
        "    test_histograms.append(hist)\n",
        "    # Add code to append the label for the video\n",
        "    # test_labels.append(label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EQmRGaNCvOr"
      },
      "source": [
        "Training a Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA-mAIj6AKxz"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='linear', probability=True)\n",
        "clf.fit(train_histograms, train_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l99vVYJrCyS3"
      },
      "source": [
        "Testing and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuHCmJpqAMa1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = clf.predict(test_histograms)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
        "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
        "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}